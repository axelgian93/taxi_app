services:
  db:
    image: postgis/postgis:16-3.4
    container_name: taxi_db
    environment:
      POSTGRES_USER: taxi
      POSTGRES_PASSWORD: taxi123
      POSTGRES_DB: taxi_app
    ports:
      - "55432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U taxi -d taxi_app -h localhost"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: taxi_redis
    command: ["redis-server", "--appendonly", "yes"]
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 20
    restart: unless-stopped

  # ---------- PERFIL PRODUCCIÓN ----------
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: taxi_api
    env_file:
      - ./backend/.env.docker
    ports:
      - "8080:8080"   # Prod expone 8080 en host
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    profiles: ["prod"]

  # ---------- MONITOREO (Prometheus + Grafana) ----------
  prometheus:
    image: prom/prometheus:v2.55.1
    container_name: taxi_prometheus
    restart: unless-stopped
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infra/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prom_data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    profiles: ["monitor"]

  grafana:
    image: grafana/grafana:11.2.0
    container_name: taxi_grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    profiles: ["monitor"]

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: taxi_alertmanager
    restart: unless-stopped
    command: ["--config.file=/etc/alertmanager/alertmanager.yml", "--log.level=info", "--config.expand-env=true"]
    environment:
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
      - ALERT_EMAIL_TO=${ALERT_EMAIL_TO:-}
      - ALERT_EMAIL_FROM=${ALERT_EMAIL_FROM:-}
      - SMTP_HOST=${SMTP_HOST:-}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USER=${SMTP_USER:-}
      - SMTP_PASS=${SMTP_PASS:-}
    volumes:
      - ./infra/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports:
      - "127.0.0.1:9093:9093"
    profiles: ["monitor"]

  # ---------- PERFIL DESARROLLO (hot-reload) ----------
  api-dev:
    image: node:22-alpine
    container_name: taxi_api_dev
    working_dir: /app
    env_file:
      - ./backend/.env.dev.docker   # si no lo tienes, usa .env.docker
    environment:
      # Asegura instalación de devDependencies dentro del contenedor
      NODE_ENV: development
      NPM_CONFIG_PRODUCTION: "false"
      # Hot reload estable en Windows
      CHOKIDAR_USEPOLLING: "1"      # necesario para hot-reload en Windows
    command: >
      sh -c "
      npm ci &&
      npx prisma generate &&
      npx prisma migrate deploy &&
      npx ts-node-dev --respawn --transpile-only src/index.ts
      "
    volumes:
      - ./backend:/app
      - node_deps:/app/node_modules
    ports:
      - "8081:8080"                 # Dev expone 8081 en host (evita colisión con prod)
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    profiles: ["dev"]

volumes:
  db_data:
  redis_data:
  prom_data:
  grafana_data:
  node_deps:
